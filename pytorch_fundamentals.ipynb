{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMawxQ0jLIPvktNF2dp0//S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbcse/deep-learning-pytorch/blob/master/pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Fundamentals\n",
        "Link: https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ],
      "metadata": {
        "id": "1PmmH7vEWb5M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHcE9a8jH8-2",
        "outputId": "cc8337e7-ac22-4176-a8f3-895afc7ab1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 14 17:00:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0             48W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Installation"
      ],
      "metadata": {
        "id": "93U5J6sXVIHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lI_d_6YIf6u",
        "outputId": "11bf79ae-f576-420f-b1a7-555accde4589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchaudio torchvision torchtext torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FjCdZYSIf3I",
        "outputId": "f401e0cf-721f-4fd6-85e2-d9986827d1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.10.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.10.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext, torchdata\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchdata-0.10.1 torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device.type\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t8rizQfCIf0B",
        "outputId": "6cc29908-2ed0-41da-e982-c878aea458c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "_DPahvkmIfw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ab51e0-8f78-477e-84c9-976f61af3dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "1. Scalar\n",
        "2. Vector\n",
        "3. Matrix"
      ],
      "metadata": {
        "id": "ldEszDb6RD9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  -----------------------Tensors---------------------\n",
        "import torch\n",
        "\n",
        "# ------------------- scalar ---------------\n",
        "\n",
        "scalar = torch.tensor(7)\n",
        "print(scalar)\n",
        "print(scalar.ndim)\n",
        "print(scalar.item())\n",
        "\n",
        "\n",
        "# ------------------- vector ---------------\n",
        "\n",
        "\n",
        "vector = torch.tensor([7,7])\n",
        "print(vector)\n",
        "print(vector.ndim)\n",
        "print(vector.shape)\n",
        "\n",
        "# ------------------ matrix --------------------\n",
        "\n",
        "matrix = torch.tensor([[7,8],[9,10]])\n",
        "print(matrix)\n",
        "print(matrix.ndim)\n",
        "print(matrix.shape)\n",
        "print(matrix[0][1])\n",
        "print(matrix[1][0])\n",
        "\n",
        "# ------------------ tensor --------------------\n",
        "\n",
        "tensor = torch.tensor([[[1,2,3],[3,6,9],[2,4,5]]])\n",
        "print(tensor)\n",
        "print(tensor.ndim)\n",
        "print(tensor.shape)\n",
        "print(tensor[0][0][1])\n",
        "\n"
      ],
      "metadata": {
        "id": "WrSQ4udhIftx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6a3a41-4267-49db-a405-47f4d973071b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------- scalar ---------------\n",
            "tensor(7)\n",
            "0\n",
            "7\n",
            "------------------- vector ---------------\n",
            "tensor([7, 7])\n",
            "1\n",
            "torch.Size([2])\n",
            "------------------ matrix --------------------\n",
            "tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n",
            "2\n",
            "torch.Size([2, 2])\n",
            "tensor(8)\n",
            "tensor(9)\n",
            "------------------ tensor --------------------\n",
            "tensor([[[1, 2, 3],\n",
            "         [3, 6, 9],\n",
            "         [2, 4, 5]]])\n",
            "3\n",
            "torch.Size([1, 3, 3])\n",
            "tensor(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors"
      ],
      "metadata": {
        "id": "pHvhGrs7RLpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3,4)\n",
        "print(random_tensor)\n",
        "print(random_tensor.ndim)\n",
        "print(random_tensor.shape)"
      ],
      "metadata": {
        "id": "q2-2FzPjIfqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651d7be7-8f66-41bd-8617-813faedc1733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8794, 0.8512, 0.4315, 0.9575],\n",
            "        [0.9425, 0.9947, 0.0878, 0.3132],\n",
            "        [0.8482, 0.9876, 0.7078, 0.3423]])\n",
            "2\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_size_tensor = torch.rand(size=(224,224,3)) ### height, width, colour channels\n",
        "print(random_image_size_tensor)\n",
        "print(random_image_size_tensor.ndim)\n",
        "print(random_image_size_tensor.shape)"
      ],
      "metadata": {
        "id": "gpXzXprfIfnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaee21f-9f4f-4b50-dc2e-8c700143f406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.0057e-01, 9.4350e-02, 6.5886e-01],\n",
            "         [1.1347e-01, 5.4693e-01, 7.4396e-01],\n",
            "         [7.1559e-01, 7.8833e-01, 3.4640e-01],\n",
            "         ...,\n",
            "         [2.0538e-01, 5.1139e-01, 8.9047e-01],\n",
            "         [8.9965e-01, 9.0255e-01, 4.1946e-01],\n",
            "         [2.8908e-01, 1.0609e-01, 6.8774e-01]],\n",
            "\n",
            "        [[4.9733e-01, 7.2923e-01, 8.2558e-01],\n",
            "         [8.9815e-01, 7.2630e-01, 2.7595e-01],\n",
            "         [9.0956e-01, 4.6738e-01, 3.2471e-01],\n",
            "         ...,\n",
            "         [9.1554e-01, 2.1126e-01, 2.6997e-01],\n",
            "         [6.3591e-01, 9.1381e-01, 3.0027e-01],\n",
            "         [8.2387e-01, 5.7666e-01, 5.0236e-01]],\n",
            "\n",
            "        [[5.0413e-01, 3.5396e-01, 1.6093e-01],\n",
            "         [5.9479e-04, 1.4588e-01, 4.2962e-01],\n",
            "         [3.8580e-01, 3.4748e-01, 9.8126e-03],\n",
            "         ...,\n",
            "         [3.5364e-01, 8.0333e-01, 6.9114e-01],\n",
            "         [2.1256e-01, 4.2593e-01, 3.3944e-02],\n",
            "         [9.3894e-01, 6.2778e-01, 4.8160e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[3.8408e-01, 7.1922e-01, 5.0482e-01],\n",
            "         [7.3283e-01, 4.8301e-01, 4.8263e-01],\n",
            "         [4.2101e-01, 8.7806e-01, 7.6474e-01],\n",
            "         ...,\n",
            "         [2.0080e-01, 9.0840e-01, 1.2289e-01],\n",
            "         [3.3582e-01, 9.3815e-01, 5.4175e-01],\n",
            "         [5.5630e-01, 6.7207e-01, 9.0816e-01]],\n",
            "\n",
            "        [[7.9780e-01, 8.3459e-01, 2.6376e-01],\n",
            "         [5.7941e-01, 9.3690e-01, 2.1975e-01],\n",
            "         [1.4703e-01, 3.8404e-01, 2.9190e-02],\n",
            "         ...,\n",
            "         [6.1665e-01, 3.1812e-01, 8.7406e-01],\n",
            "         [9.9233e-01, 5.7338e-01, 5.3684e-01],\n",
            "         [2.9566e-01, 6.4815e-01, 7.6491e-01]],\n",
            "\n",
            "        [[1.6726e-01, 8.2830e-01, 9.8140e-01],\n",
            "         [2.4784e-01, 2.2133e-01, 8.9762e-01],\n",
            "         [2.8388e-01, 6.8106e-01, 5.6667e-01],\n",
            "         ...,\n",
            "         [9.9693e-01, 2.5647e-01, 8.6856e-01],\n",
            "         [5.6356e-01, 9.5003e-01, 5.6033e-01],\n",
            "         [6.1155e-01, 6.4147e-02, 4.1163e-01]]])\n",
            "3\n",
            "torch.Size([224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and Ones Tensors\n",
        "* Zeros: `0`\n",
        "* Ones: `1`"
      ],
      "metadata": {
        "id": "1J6QM37fVcnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero = torch.zeros(size=(3,4))\n",
        "print(zero)\n",
        "print(zero.dtype)"
      ],
      "metadata": {
        "id": "CaTvnhp_Ifkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad8c078-6c3e-472b-c6c6-084d52c12106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero * random_tensor"
      ],
      "metadata": {
        "id": "LKMQEZHbIfZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0085b3c8-8fbb-4f18-e9f1-2602b1578b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one = torch.ones(size=(3,4))\n",
        "print(one)\n",
        "print(one.dtype)"
      ],
      "metadata": {
        "id": "X0a_UcVbIfNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ad80fb-f7e8-441a-f1cf-e91cf0b147f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Range of Tensors"
      ],
      "metadata": {
        "id": "Ko2tt4jqfxre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# range of tensors\n",
        "\n",
        "range_tensors=torch.arange(start=0,end=101,step=10)"
      ],
      "metadata": {
        "id": "Bz1_7A0BNUdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors like\n",
        "\n",
        "ten_zeros = torch.zeros_like(input=range_tensors)\n",
        "print(ten_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFbcg3vcSDQC",
        "outputId": "7b4558b1-faff-4a52-dd0f-ed3405e5e15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor data types"
      ],
      "metadata": {
        "id": "KHIgOcy3f6CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor data types\n",
        "float_32_tensor = torch.tensor([3.0,6.0,9.0],dtype=None,device=None,requires_grad=False)\n",
        "print(float_32_tensor)\n",
        "print(float_32_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXkJijMkSDMk",
        "outputId": "43b1cb2e-4a0a-4e2f-c162-18cdf9d94e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 6., 9.])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor=float_32_tensor.type(torch.float16)\n",
        "print(float_16_tensor)\n",
        "print(float_16_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOXl7y8aSDJz",
        "outputId": "ba703d1f-86e3-41f1-ec05-f602cddfdb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 6., 9.], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor * float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb3_AuiASDG0",
        "outputId": "c21ab6c5-48a2-4ab0-9061-b5b284b7d152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor=torch.tensor([3,6,9],dtype=torch.int32)\n",
        "print(int_32_tensor)\n",
        "print(int_32_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3wca1ykSDEI",
        "outputId": "1f3fea66-8779-4f0a-d7a4-9441ca84f219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 6, 9], dtype=torch.int32)\n",
            "torch.int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor*int_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWwmy8LOSDBy",
        "outputId": "1bd4162c-3618-4320-c809-194ef5769c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details about Tensor"
      ],
      "metadata": {
        "id": "cVwElBvLgE-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find out details about tensors\n",
        "\n",
        "random_tensor = torch.rand(3,4)\n",
        "print(random_tensor)\n",
        "print(random_tensor.dtype)\n",
        "print(random_tensor.shape)\n",
        "print(random_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjRiC0wVSC-Q",
        "outputId": "967fd1da-dfec-4393-af1d-1b68aa3c5b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1950, 0.2895, 0.8884, 0.9062],\n",
            "        [0.8927, 0.4247, 0.7139, 0.7026],\n",
            "        [0.9266, 0.4034, 0.9265, 0.9936]])\n",
            "torch.float32\n",
            "torch.Size([3, 4])\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations\n",
        "1. Addition\n",
        "2. Substraction\n",
        "3. Multiplication\n",
        "4. Division\n",
        "5. Matrix Multiplication"
      ],
      "metadata": {
        "id": "-4GrKm8wgKVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor operations: addition, substraction, multiplication, division, matrix multiplication\n",
        "\n",
        "tensor = torch.tensor([1,2,3])\n",
        "print(f\"Addition: {tensor + 10}\")\n",
        "print(f\"Substraction: {tensor - 1}\")\n",
        "print(f\"Multiplication: {tensor * 2}\")\n",
        "print(f\"Division: {tensor / 2}\")\n",
        "\n",
        "# matrix multiplication (dot product)\n",
        "\n",
        "print(tensor * tensor)\n",
        "print(tensor.matmul(tensor))\n",
        "\n",
        "torch.matmul(torch.rand(3,10),torch.rand(10,3))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqx5NG17SC7R",
        "outputId": "f59a4caf-e80c-44e4-d128-8226739c13f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: tensor([11, 12, 13])\n",
            "Substraction: tensor([0, 1, 2])\n",
            "Multiplication: tensor([2, 4, 6])\n",
            "Division: tensor([0.5000, 1.0000, 1.5000])\n",
            "tensor([1, 4, 9])\n",
            "tensor(14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.6671, 1.8327, 1.1321],\n",
              "        [2.7721, 2.6454, 1.1017],\n",
              "        [3.4309, 3.5116, 2.1519]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "tensor_b = torch.tensor([[7,10],[8,11],[9,12]])\n",
        "print(\"Tensor A: \\n\",tensor_a)\n",
        "print(\"Tensor B: \\n\",tensor_b)\n",
        "\n",
        "print(\"Tensor A Shape: \\n\",tensor_a.shape)\n",
        "print(\"Tensor B Shape: \\n\", tensor_b.shape)\n",
        "\n",
        "# matrix transpose\n",
        "print(\"Tensor B Transpose: \\n\",tensor_b.T)\n",
        "print(\"Tesnsor B Transpose Shape:\\n \",tensor_b.T.shape)\n",
        "\n",
        "print(\"Multiplication Output: \\n\",torch.mm(tensor_a,tensor_b.T))\n",
        "print(\"Multiplication Output Shape: \\n\",torch.mm(tensor_a,tensor_b.T).shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRNDg-6kSC4U",
        "outputId": "60c39599-6dc2-4aa3-d8c1-b0b706108aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A: \n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "Tensor B: \n",
            " tensor([[ 7, 10],\n",
            "        [ 8, 11],\n",
            "        [ 9, 12]])\n",
            "Tensor A Shape: \n",
            " torch.Size([3, 2])\n",
            "Tensor B Shape: \n",
            " torch.Size([3, 2])\n",
            "Tensor B Transpose: \n",
            " tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "Tesnsor B Transpose Shape:\n",
            "  torch.Size([2, 3])\n",
            "Multiplication Output: \n",
            " tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "Multiplication Output Shape: \n",
            " torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor aggregation"
      ],
      "metadata": {
        "id": "MxANkX7kgZ1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor aggregation\n",
        "\n",
        "x = torch.arange(1,100,7)\n",
        "print(x)\n",
        "print(\"Minimum: \", x.min())\n",
        "print(\"Maximum: \", x.max())\n",
        "print(\"Mean: \", x.type(torch.float32).mean())\n",
        "print(\"Sum: \",x.sum())"
      ],
      "metadata": {
        "id": "4hBWFriDSC1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f00e16-7a62-4839-f43b-28c75ed57c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  8, 15, 22, 29, 36, 43, 50, 57, 64, 71, 78, 85, 92, 99])\n",
            "Minimum:  tensor(1)\n",
            "Maximum:  tensor(99)\n",
            "Mean:  tensor(50.)\n",
            "Sum:  tensor(750)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Minimum and Maximum"
      ],
      "metadata": {
        "id": "tCpRoky_geQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional min and max\n",
        "\n",
        "print(\"Tensor: \",x)\n",
        "\n",
        "print(\"Positional Minimum: \",x.argmin())\n",
        "print(\"Positional Maximum: \",x.argmax())"
      ],
      "metadata": {
        "id": "cs-qs_8dSCx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0e8692-7f94-4200-ad05-3200b7c813cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:  tensor([ 1,  8, 15, 22, 29, 36, 43, 50, 57, 64, 71, 78, 85, 92, 99])\n",
            "Positional Minimum:  tensor(0)\n",
            "Positional Maximum:  tensor(14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping, Viewing, Squeeezing, Unsqueezing and Stacking Tensors"
      ],
      "metadata": {
        "id": "lHs84qxoVnWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.arange(1.,10.)\n",
        "print(x, x.shape)"
      ],
      "metadata": {
        "id": "2DYkpqnYSCuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bc7247-645c-4f41-ab41-75e7f0d1e3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding an extra dimension\n",
        "\n",
        "x_reshaped = x.reshape(1,9)\n",
        "print(x_reshaped, x_reshaped.shape)\n",
        "x_reshaped = x.reshape(9,1)\n",
        "print(x_reshaped, x_reshaped.shape)\n"
      ],
      "metadata": {
        "id": "vdyvhHgdX4z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9212b294-96b7-410f-890a-c11833c7d5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9])\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]]) torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changeing the view\n",
        "\n",
        "y = x.view(1,9)\n",
        "print(y, y.shape)\n",
        "\n",
        "y[:,0] = 3\n",
        "print(y, x)"
      ],
      "metadata": {
        "id": "MXFE-aPcX4sH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9936c3a2-6ad2-4609-f84f-1be5ab09e832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9])\n",
            "tensor([[3., 2., 3., 4., 5., 6., 7., 8., 9.]]) tensor([3., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stack tensor on the top of each other\n",
        "\n",
        "x_stacked = torch.stack([x,x,x,x],dim=0)\n",
        "print(x_stacked)\n",
        "\n",
        "y_stacked = torch.stack([x,x,x,x],dim=1)\n",
        "print(y_stacked)"
      ],
      "metadata": {
        "id": "hhxC3S-PX4i3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b73440-d5cc-4f8e-9128-fe010f4ef9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [3., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [3., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [3., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [8., 8., 8., 8.],\n",
            "        [9., 9., 9., 9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squeezing a tensor\n",
        "\n",
        "x_reshaped = x.reshape(1,9)\n",
        "print(\"Previous Tensor: \",x_reshaped,\"\\nPrevious Shape: \", x_reshaped.shape)\n",
        "\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(\"Squeezed Tensor: \",x_squeezed,\"\\nSqueezed Shape:\", x_squeezed.shape)"
      ],
      "metadata": {
        "id": "BMeHC6kZX4Z2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bbf647-0b7e-4ad0-acb9-331877783ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous Tensor:  tensor([[3., 2., 3., 4., 5., 6., 7., 8., 9.]]) \n",
            "Previous Shape:  torch.Size([1, 9])\n",
            "Squeezed Tensor:  tensor([3., 2., 3., 4., 5., 6., 7., 8., 9.]) \n",
            "Squeezed Shape: torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueezing a tensor\n",
        "\n",
        "print(\"Previous Tensor: \",x_squeezed,\"\\nPrevious Shape: \", x_squeezed.shape)\n",
        "\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(\"Unsqueezed Tensor: \",x_unsqueezed,\"\\nUnsqueezed Shape:\", x_unsqueezed.shape)\n",
        "\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(\"Unsqueezed Tensor: \",x_unsqueezed,\"\\nUnsqueezed Shape:\", x_unsqueezed.shape)"
      ],
      "metadata": {
        "id": "HH-vtqfvX4QZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "150a1821-67c6-4441-9fb0-3ac2adecbc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous Tensor:  tensor([3., 2., 3., 4., 5., 6., 7., 8., 9.]) \n",
            "Previous Shape:  torch.Size([9])\n",
            "Unsqueezed Tensor:  tensor([[3., 2., 3., 4., 5., 6., 7., 8., 9.]]) \n",
            "Unsqueezed Shape: torch.Size([1, 9])\n",
            "Unsqueezed Tensor:  tensor([[3.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]]) \n",
            "Unsqueezed Shape: torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permuting a Tensor"
      ],
      "metadata": {
        "id": "XRa3YWPugqy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# permuting a tensor\n",
        "\n",
        "x_original = torch.rand(size=(224,224,3))\n",
        "\n",
        "x_permuted = x_original.permute(2,0,1)\n",
        "print(x_original.shape)\n",
        "print(x_permuted.shape)\n",
        "print(x_original[0,0,0])\n",
        "print(x_permuted[0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUdUgsTAgrgn",
        "outputId": "72916fd7-2b25-421d-eab5-fca7a87ed646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([224, 224, 3])\n",
            "torch.Size([3, 224, 224])\n",
            "tensor(0.8457)\n",
            "tensor(0.8457)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting data from tensors (indexing)"
      ],
      "metadata": {
        "id": "eNqvSeo0jmF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor\n",
        "\n",
        "import torch\n",
        "\n",
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "print(x, x.shape)\n",
        "print(x[0])\n",
        "print(x[0][0])\n",
        "print(x[0][0][0])\n",
        "print(x[0][1][1])\n",
        "print(x[0][2][2])\n",
        "print(x[:,0])\n",
        "print(x[:,:,1])\n",
        "print(x[:,1,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckXqQelagrYq",
        "outputId": "e5710e57-d504-4157-ff88-0928431074a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([1, 2, 3])\n",
            "tensor(1)\n",
            "tensor(5)\n",
            "tensor(9)\n",
            "tensor([[1, 2, 3]])\n",
            "tensor([[2, 5, 8]])\n",
            "tensor([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch tensors and NumPy"
      ],
      "metadata": {
        "id": "szL7bTg0nuJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "print(array, array.dtype)\n",
        "print(tensor, tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U8AIQbygrQz",
        "outputId": "aadb56bf-89c9-482a-d88e-bf759d383d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6. 7.] float64\n",
            "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64) torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the value of array\n",
        "\n",
        "array += 1\n",
        "print(array, array.dtype)\n",
        "print(tensor, tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li_hAdM9grIO",
        "outputId": "b5aef679-d105-45d3-c63c-dc35ce258434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 3. 4. 5. 6. 7. 8.] float64\n",
            "tensor([2., 3., 4., 5., 6., 7., 8.], dtype=torch.float64) torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor to numpy array\n",
        "\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "print(tensor, tensor.dtype)\n",
        "print(numpy_tensor, numpy_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss0FQVTLgq8x",
        "outputId": "5b66e761-6d82-40d8-c1c9-1e121894ff47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.]) torch.float32\n",
            "[1. 1. 1. 1. 1. 1. 1.] float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the value of tensor\n",
        "\n",
        "tensor += 1\n",
        "print(tensor, tensor.dtype)\n",
        "print(numpy_tensor, numpy_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux9VYKfmt68X",
        "outputId": "3e3adce8-2514-4ab1-d8fb-51fd65c92fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2., 2., 2.]) torch.float32\n",
            "[2. 2. 2. 2. 2. 2. 2.] float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Reproducibility"
      ],
      "metadata": {
        "id": "Lo1VOcLju7SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating two random tensors\n",
        "\n",
        "random_tensor_A = torch.rand(3,4)\n",
        "random_tensor_B = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-AHVV2Mt611",
        "outputId": "962093d0-89df-4e56-8ded-c771eb41f943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3511, 0.8650, 0.6631, 0.7868],\n",
            "        [0.0661, 0.9351, 0.5158, 0.0199],\n",
            "        [0.7709, 0.9698, 0.6839, 0.3402]])\n",
            "tensor([[0.8692, 0.5501, 0.5928, 0.1305],\n",
            "        [0.4752, 0.8511, 0.0763, 0.5196],\n",
            "        [0.1711, 0.5042, 0.2348, 0.7692]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed\n",
        "\n",
        "import torch\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH9OdVRBt6tZ",
        "outputId": "52dec103-de06-4a0e-d34f-364281f32e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for GPU access in PyTorch"
      ],
      "metadata": {
        "id": "o5ke74mE0Joa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DOinq9Tt6k2",
        "outputId": "1cd50657-fd49-4579-af39-576f51c78a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 18 16:08:20 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vhcvRcxt6c_",
        "outputId": "e16cec7e-e878-48f0-ed20-57eff84ee37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup device agnostic code\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zs6mOUR30UkQ",
        "outputId": "7904a9fa-c048-4299-cea2-da3fb857a19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count number of gpus\n",
        "\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMDVldSF0Ug0",
        "outputId": "7ed1761c-aac2-44bf-8466-5fcabbc4c8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# putting tensors and models on the GPU\n",
        "\n",
        "tensor = torch.tensor([1,2,3])\n",
        "\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "print(tensor_on_gpu, tensor_on_gpu.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSst2EcO0Ud8",
        "outputId": "9e167a25-6b69-4a1c-9955-d1c1a20b7699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n",
            "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor back on cpu\n",
        "\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Nd-TSe0Uax",
        "outputId": "bcc152fd-6138-401c-af8a-29b945a72d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}